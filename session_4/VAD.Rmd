---
title: "Session 4 in-class exercise"
author: "J.M.T. Roos"
date: "1 June 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, tidy=TRUE, cache=FALSE)
```

Install package `gutenbergr`

```{r eval = FALSE}
install.packges('gutenbergr', dependencies = TRUE)
```

Load the library

```{r}
library(gutenbergr)
```

Get a list of H.P. Lovecraft books

```{r}
gutenberg_works( gutenberg_author_id == 34724, distinct=FALSE )
```

Download a book

```{r cache=TRUE}
dunwich <- gutenberg_download( 50133 )
```

Take a look
```{r message=FALSE}
library(dplyr)
dunwich$text %>% head(10) 
```

Remove the first 5 lines, and any line that is blank or has a single (page) number

```{r}
library(stringr)
dunwich_2 <- dunwich %>% filter( text != "" & !str_detect(text,'^[0-9]+$') )
dunwich_2 %>% select(text) %>% as.data.frame %>% head(30)
```

Fix encoding problems

```{r}
dunwich_3 <- dunwich_2$text %>% stringi::stri_encode(., from='ISO-8859-1', to='UTF-8')
```

Download the VAD data

```{r cache=TRUE}
VAD_scores_url <- 'http://crr.ugent.be/papers/Ratings_Warriner_et_al.csv'
VAD <- readr::read_csv(VAD_scores_url) %>% select(Word,valence=V.Mean.Sum,arousal=A.Mean.Sum,dominance=D.Mean.Sum)
```

Load `tm`

```{r message = FALSE}
library(tm)
```

Create a vector corpus

```{r}
dunwich_corpus <- dunwich_3 %>% VectorSource %>% Corpus
dunwich_corpus
```

Clean things up (note: we are not stemming words)

```{r tidy=FALSE}
dunwich_corpus_cleaned <- dunwich_corpus %>%
  tm_map(content_transformer(tolower)) %>%      # lower case
  tm_map(removePunctuation) %>%                 # remove punctuation
  tm_map(removeWords, stopwords('english')) %>% # remove common words
  tm_map(stripWhitespace)                       # remove white space
```

Generate a term-document matrix

```{r}
tdm <- dunwich_corpus_cleaned %>% TermDocumentMatrix
tdm %>% findFreqTerms(lowfreq=30)
```

Join with the VAD scores

```{r}
tdm_long <- with( tdm, data_frame( term = i, document = j, count = v ) ) %>% mutate( term = factor(term, labels = Terms(tdm)) %>% as.character ) 
tdm_scored <- tdm_long %>% inner_join( VAD, by=c('term'='Word') )
tdm_scored
```

Summarize the book line by line by averaging scores
```{r tidy=FALSE}
line_scores <- tdm_scored %>% 
  transmute(line = document, 
            valence = valence * count, 
            arousal = arousal * count, 
            dominance = dominance * count) %>% 
  group_by(line) %>% 
  summarise_each(funs(sum))
```

Tidy and visualize

```{r message=FALSE, warning=FALSE}
library(tidyr)
library(ggplot2)
line_scores_2 <- line_scores %>% gather( dimension, score, -line )
g <- ggplot( line_scores_2, aes( x = line, y = score, colour = dimension ) )
g + geom_point()
```

Smooth

```{r}
g + geom_smooth()
```